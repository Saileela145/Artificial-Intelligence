art 1 â€“ Classical AI: The Evolution of Search Algorithms
1ï¸âƒ£ BFS â€“ The First Step
Problem in early AI:
When researchers started working on pathfinding and puzzle-solving in the 1950sâ€“60s, they needed a method that would guarantee the shortest path in unweighted problems.

Solution invented:
Breadth-First Search â€” Explore the graph level by level, visiting all neighbors before moving deeper.

How it works:

Use a Queue (FIFO) to keep track of frontier nodes.

Visit each nodeâ€™s neighbors in order.

Strengths:

Finds shortest path in unweighted graphs.

Simple to implement.

Weakness:

High memory usage for wide/deep graphs.

2ï¸âƒ£ DFS â€“ The Memory Saver
Problem with BFS:
Needed too much memory â€” storing all frontier nodes was impractical for big graphs.

Solution invented:
Depth-First Search â€” Dive deep into one path before backtracking.

How it works:

Use a Stack (LIFO) or recursion.

Follow one branch until you canâ€™t go further, then backtrack.

Strengths:

Very low memory usage.

Weakness:

Does not guarantee shortest path.

Can get stuck in deep or infinite loops.

3ï¸âƒ£ Best First Search â€“ The First â€œSmartâ€ Search
Problem with DFS/BFS:
Both explored blindly â€” wasted time on paths that clearly werenâ€™t leading to the goal.

Solution invented:
Best First Search â€” Use a heuristic function 
â„
(
ğ‘›
)
h(n) to estimate how close a node is to the goal, then always choose the closest-looking node.

Strengths:

Can be much faster if heuristic is good.

Weakness:

Might give wrong (non-optimal) path.

Bad heuristic = bad performance.

4ï¸âƒ£ A* Search â€“ The Gold Standard
Problem with Best First Search:
Only cared about estimated closeness, not the actual cost taken so far.

Solution invented:
A* â€” Combines cost so far 
ğ‘”
(
ğ‘›
)
g(n) and heuristic 
â„
(
ğ‘›
)
h(n):

ğ‘“
(
ğ‘›
)
=
ğ‘”
(
ğ‘›
)
+
â„
(
ğ‘›
)
f(n)=g(n)+h(n)
Strengths:

Finds optimal path if heuristic is admissible.

Weakness:

Still memory-heavy for very large graphs.

5ï¸âƒ£ AO* Search â€“ The Problem Solver for Complex Tasks
Problem with A*:
Couldnâ€™t handle AND-OR problems (tasks requiring multiple sub-tasks).

Solution invented:
AO* â€” Works on AND-OR graphs, expanding promising nodes and handling dependencies.

Strengths:

Solves multi-step dependent problems.

Weakness:

Complex to implement.

Part 2 â€“ Modern AI: Machine Learning Steps
1ï¸âƒ£ Data Preprocessing â€“ The Foundation
Problem:
Raw datasets had missing values, mixed formats, and categorical data models couldnâ€™t understand.

Solution:
Preprocessing: clean, encode, and prepare the data.

2ï¸âƒ£ Feature Scaling â€“ Leveling the Playing Field
Problem:
Features had different ranges â€” large values dominated smaller ones.

Solution:
Standardization (mean=0, std=1) or Min-Max scaling (0 to 1).

3ï¸âƒ£ Train-Test Split â€“ Honest Evaluation
Problem:
Testing on the same data used for training gave misleadingly high accuracy.

Solution:
Split into training set and testing set (e.g., 80%/20%).

4ï¸âƒ£ Evaluation Metrics â€“ Beyond Accuracy
Problem:
Accuracy failed for imbalanced datasets.

Solution:
Precision, recall, F1-score, confusion matrix.

5ï¸âƒ£ Overfitting/Underfitting â€“ The Balancing Act
Problem:
Models either memorized data (overfit) or missed patterns (underfit).

Solution:
Regularization, cross-validation, better data/features.

