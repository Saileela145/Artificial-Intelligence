# ¬†‚úÖ Day 3 - Artificial Intelligence

## üìò Topic: Supervised Learning ‚Äì Classification

### üîç What is Classification?

* **Classification** is a type of **Supervised Learning** in which a model learns from **labeled data** and predicts **categories or class labels**.
* It answers questions like:

  * Will the student **Pass or Fail**?
  * Is this email **Spam or Not Spam**?
  * Is the tumor **Benign or Malignant**?

### üéØ What is Supervised Learning?

* **Supervised Learning** means learning from data where both **input (features)** and **output (labels)** are known.
* The model is trained on this labeled data to learn the relationship between input and output.

### ‚öñÔ∏è Classification vs Regression

* **Classification** ‚Üí Predicts **discrete categories** (like Yes/No, Spam/Not Spam).
* **Regression** ‚Üí Predicts **continuous values** (like price, temperature, or salary).

### üß† Input and Output

* **Input Features:** The data we use to make a prediction.
  *Example:* Math and Science marks.
* **Output Label:** The category we want to predict.
  *Example:* Result ‚Üí Pass or Fail.

### üõ†Ô∏è Steps in Building a Classification Model
| Step No. | Step Name              | Description                                                                 |
|----------|---------------------- -|-----------------------------------------------------------------------------|
| 1        | Data Collection        | Gather labeled data (input features + output labels)                        |
| 2        | Data Preprocessing     | Clean the data: handle missing values, encode categories, normalize         |
| 3        | Split Dataset          | Divide into training and testing sets (commonly 80:20)                      |
| 4        | Choose Algorithm       | Select a suitable classification algorithm (Logistic Regression, KNN, etc.) |
| 5        | Train Model            | Fit the model using training data                                           |
| 6        | Evaluate Model         | Use test data to check model performance (accuracy, precision, etc.)        |
| 7        | Predict                | Predict labels for new/unseen input data                                    |

1. **Collect Data:** Get data with inputs and labels.
2. **Preprocess Data:** Clean, normalize, or encode the data.
3. **Split Dataset:** Usually split into 80% training and 20% testing.
4. **Choose Algorithm:** Select a model (Logistic Regression, KNN, etc.).
5. **Train the Model:** Use training data to teach the model.
6. **Evaluate the Model:** Use test data to measure accuracy.
7. **Make Predictions:** Use model to predict for new data.

### üß™ Common Classification Algorithms

* **Logistic Regression:** Best for Yes/No predictions.
* **K-Nearest Neighbors (KNN):** Classifies based on similar neighbors.
* **Decision Tree:** Makes decisions by asking yes/no questions.
* **Support Vector Machine (SVM):** Finds the best boundary to separate classes.
* **Naive Bayes:** Uses probability and Bayes‚Äô theorem to classify.
EXAMPLE:
 ## üìä Sample Classification Dataset

| Math Marks | Science Marks  | Result |
|------------|----------------|--------|
| 85         | 90             | Pass   |
| 45         | 40             | Fail   |
| 70         | 75             | Pass   |
| 30         | 20             | Fail   |

üëâ **Input Given:** `[60, 65]`  
üëâ **Model Prediction:** `Pass`

### üìè Model Evaluation Metrics

* **Accuracy:** How many predictions were correct.
* **Precision:** How many predicted positives were actually correct.
* **Recall:** How many actual positives the model identified.
* **Confusion Matrix:** Table showing true/false positives and negatives.

### üåç Real-Life Applications


| Domain        | Use Case                                      | Example                                                                |
|---------------|-----------------------------------------------|------------------------------------------------------------------------|
| Healthcare    | Disease diagnosis                             | Classify tumor as benign or malignant                                  |
| Email         | Spam detection                                | Gmail filters spam from inbox                                          |
| Banking       | Loan risk prediction                          | Classify customers as risky or safe borrowers                          |
| Social Media  | Content moderation                            | Detect hate speech or abuse in posts                                   |
| Security      | Face recognition                              | Unlocking phone or verifying identity                                  |


* **Healthcare:** Classify tumor as benign or malignant.
* **Email Filtering:** Detect spam vs non-spam.
* **Banking:** Predict whether a person is a risky or safe borrower.
* **Social Media:** Detect hate speech or offensive content.
* **Security:** Face recognition to unlock devices.

### ‚úÖ Final Summary

* **Classification** helps predict labels from known data.
* It is a **supervised learning** method.
* Used in **many industries** for smart decision-making.
* Common tools: **Logistic Regression, KNN, SVM, Decision Trees**.
* Evaluated using **Accuracy, Precision, Recall, Confusion Matrix**.

| üîπ Concept                üîç Description                                                             |
|--------------------------|----------------------------------------------------------------------------|
| Supervised Learning      | Learning from data with known input-output pairs (labeled data)            |
| Classification           | Predicting discrete labels or categories                                   |
| Algorithms Used          | Logistic Regression, KNN, SVM, Naive Bayes, Decision Tree                  |
| Performance Evaluation   | Accuracy, Precision, Recall, Confusion Matrix                              |
| Applications             | Healthcare, Spam Filters, Security Systems, Financial Risk Assessment      | 

# One shot concent:

## üìò Topic: Supervised Learning ‚Äì Classification

| üî¢ S.No | üß† Topic                         | üìñ Meaning                                                                                     | üß™ Example                                                                                           |
|--------|----------------------------------|------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|
| 1      | Classification                   | Predicting categories or labels from data (a type of supervised learning)                      | Email classified as "Spam" or "Not Spam"                                                             |
| 2      | Supervised Learning              | Learning from labeled data where both input and output are known                               | Predicting result (Pass/Fail) based on marks                                                         |
| 3      | Classification vs Regression     | Classification predicts categories; Regression predicts continuous values                      | Classification: Pass/Fail<br>Regression: Predicting salary                                           |
| 4      | Input Features                   | Data used to make predictions                                                                  | Marks in Math and Science                                                                            |
| 5      | Output Label                     | The category or class to be predicted                                                          | Result ‚Üí Pass or Fail                                                                                |
| 6      | Dataset Splitting                | Dividing data into training and testing sets                                                   | 80% for training, 20% for testing                                                                    |
| 7      | Logistic Regression              | A classification algorithm for binary outcomes                                                 | Predicting Yes/No decisions like ‚ÄúBuy‚Äù or ‚ÄúNot Buy‚Äù                                                  |
| 8      | K-Nearest Neighbors (KNN)        | Classifies based on closest data points (neighbors)                                            | Classify a fruit based on nearby fruits with similar features                                        |
| 9      | Decision Tree                    | Uses a tree-like flowchart of decisions                                                        | Is age > 18? Yes ‚Üí Check income, No ‚Üí Deny loan                                                      |
| 10     | Support Vector Machine (SVM)     | Finds the best boundary (hyperplane) between two classes                                       | Separate cats and dogs using image features                                                          |
| 11     | Naive Bayes                      | Based on probability and Bayes' Theorem                                                        | Text classification (e.g., news, sentiment analysis)                                                 |
| 12     | Accuracy                         | Percentage of correct predictions                                                              | If 8 out of 10 are correct, accuracy = 80%                                                           |
| 13     | Precision                        | Out of predicted positives, how many are actually correct                                      | High precision means fewer false positives                                                           |
| 14     | Recall                           | Out of all actual positives, how many are correctly predicted                                  | High recall means fewer false negatives                                                              |
| 15     | Confusion Matrix                 | A table showing TP (true positive), TN, FP, FN results                                         | Helps evaluate the classification model                                                              |
| 16     | Real-life Use Case ‚Äì Healthcare  | Diagnosing diseases (e.g., classifying tumor as benign or malignant)                          | Breast cancer detection model                                                                        |
| 17     | Real-life Use Case ‚Äì Email Filter| Classify email as spam or not                                                                  | Gmail spam classification                                                                            |
| 18     | Real-life Use Case ‚Äì Banking     | Classify loan applications as safe or risky                                                    | Loan approval using classification model                                                             |
| 19     | Real-life Use Case ‚Äì Social Media| Detect hate speech, fake news, etc.                                                            | Facebook or Twitter moderation                                                                       |
| 20     | Real-life Use Case ‚Äì Security    | Face recognition and identity verification                                                     | Phone face unlock using classification                                                               |
